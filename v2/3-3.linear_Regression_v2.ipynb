{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 1.x의 Linear Regression \n",
    "~~~\n",
    "import tensorflow as tf\n",
    "\n",
    "# 선형회귀 모델(Wx + b)을 정의합니다.\n",
    "W = tf.Variable(tf.random_normal(shape=[1]))   \n",
    "b = tf.Variable(tf.random_normal(shape=[1]))\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W*x + b\n",
    "\n",
    "# placeholder를 정의합니다.\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "loss = tf.reduce_mean(tf.square(linear_model - y)) # MSE 손실함수 \\mean{(y' - y)^2}\n",
    "\n",
    "# 최적화를 위한 그라디언트 디센트 옵티마이저를 정의합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# 트레이닝을 위한 입력값과 출력값을 준비합니다. \n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "# 세션을 실행하고 파라미터(W,b)를 noraml distirubtion에서 추출한 임의의 값으로 초기화합니다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 경사하강법을 1000번 수행합니다.\n",
    "for i in range(1000):\n",
    "  sess.run(train_step, feed_dict={x: x_train, y: y_train})\n",
    "\n",
    "# 테스트를 위한 입력값을 준비합니다.\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "\n",
    "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n",
    "# 예상되는 참값 : [7, 10, 11, 12]\n",
    "print(sess.run(linear_model, feed_dict={x: x_test}))\n",
    "\n",
    "sess.close()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 선형회귀 모델(Wx + b)을 위한 tf.Variable을 선언합니다.\n",
    "W = tf.Variable(tf.random.normal(shape=[1]))\n",
    "b = tf.Variable(tf.random.normal(shape=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프를 생성하는 부분을 @tf.function을 사용하여 함수로 구별한다. \n",
    "tf.function은 파이썬 코드를 이식 가능하고 높은 성능의 텐서플로 그래포 코드로 변환해준다.  \n",
    "tf.function의 특징은 오토 그래프(AutoGraph)이다. 이는 자연스러운 파이썬 문법을 활용해서  \n",
    "그래프 코드를 작성할 수 있도록 돕는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def linear_model(x):\n",
    "  return W*x + b\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "# MSE 손실함수 \\mean{(y' - y)^2}\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "# 최적화를 위한 그라디언트 디센트 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "# 최적화를 위한 function을 정의합니다.\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = linear_model(x)\n",
    "    loss = mse_loss(y_pred, y)\n",
    "  gradients = tape.gradient(loss, [W, b])\n",
    "  optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.9996705  9.998788  10.998493  11.998199 ]\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝을 위한 입력값과 출력값을 준비합니다.\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "# 경사하강법을 1000번 수행합니다.\n",
    "for i in range(1000):\n",
    "  train_step(x_train, y_train)\n",
    "\n",
    "# 테스트를 위한 입력값을 준비합니다.\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "\n",
    "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n",
    "# 예상되는 참값 : [7, 10, 11, 12]\n",
    "print(linear_model(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

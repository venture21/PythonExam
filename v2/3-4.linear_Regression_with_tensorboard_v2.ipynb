{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 1.x에서 Linear Regression모델을 TensorBoard 출력하기\n",
    "~~~\n",
    "import tensorflow as tf\n",
    "\n",
    "# 선형회귀 모델(Wx + b)을 정의합니다.\n",
    "W = tf.Variable(tf.random_normal(shape=[1]), name=\"W\")   \n",
    "b = tf.Variable(tf.random_normal(shape=[1]), name=\"b\")\n",
    "\n",
    "x = tf.placeholder(tf.float32, name=\"x\")\n",
    "\n",
    "linear_model = W*x + b\n",
    "\n",
    "# True Value를 입력받기위한 플레이스홀더를 정의합니다.\n",
    "y = tf.placeholder(tf.float32, name=\"y\")\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "loss = tf.reduce_mean(tf.square(linear_model - y)) # MSE 손실함수 \\mean{(y' - y)^2}\n",
    "\n",
    "# 텐서보드를 위한 요약정보(scalar)를 정의합니다.\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# 최적화를 위한 옵티마이저를 정의합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# 트레이닝을 위한 입력값과 출력값을 준비합니다. \n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "# 세션을 실행하고 파라미터(W,b)를 noraml distirubtion에서 추출한 임의의 값으로 초기화합니다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 텐서보드 요약정보들을 하나로 합칩니다.\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# 텐서보드 summary 정보들을 저장할 폴더 경로를 설정합니다.\n",
    "tensorboard_writer = tf.summary.FileWriter('./tensorboard_log', sess.graph)\n",
    "\n",
    "# 경사하강법을 1000번 수행합니다.\n",
    "for i in range(1000):\n",
    "  sess.run(train_step, feed_dict={x: x_train, y: y_train})\n",
    "\n",
    "  # 매스텝마다 텐서보드 요약정보값들을 계산해서 지정된 경로('./tensorboard_log')에 저장합니다.\n",
    "  summary = sess.run(merged, feed_dict={x: x_train, y: y_train})\n",
    "  tensorboard_writer.add_summary(summary, i)\n",
    "\n",
    "# 테스트를 위한 입력값을 준비합니다.\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "\n",
    "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n",
    "# 예상되는 참값 : [7, 10, 11, 12]\n",
    "print(sess.run(linear_model, feed_dict={x: x_test}))\n",
    "\n",
    "sess.close()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 2.x에서 Linear Regression모델을 TensorBoard로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "!del tensorboard_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 선형회귀 모델(Wx + b)을 위한 tf.Variable을 선언합니다.\n",
    "W = tf.Variable(tf.random.normal(shape=[1]))\n",
    "b = tf.Variable(tf.random.normal(shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def linear_model(x):\n",
    "  return W*x + b\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "# MSE 손실함수 \\mean{(y' - y)^2}\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "# 최적화를 위한 function을 정의합니다.\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = linear_model(x)\n",
    "    loss = mse_loss(y_pred, y)\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', loss, step=optimizer.iterations)\n",
    "  gradients = tape.gradient(loss, [W, b])\n",
    "  optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x000001E64E5E8F98>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x000001E64E5E8F98>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x000001E64E5E8F98>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "WARNING: AutoGraph could not transform <bound method DescriptorBase.GetOptions of <google.protobuf.descriptor.Descriptor object at 0x000001E64E5E8F98>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: LIVE_VARS_IN\n",
      "[ 6.9952087  9.982372  10.978093  11.973815 ]\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝을 위한 입력값과 출력값을 준비합니다.\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]    \n",
    "    \n",
    "# 최적화를 위한 그라디언트 디센트 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "# 텐서보드 summary 정보들을 저장할 폴더 경로를 설정합니다.\n",
    "summary_writer = tf.summary.create_file_writer('./tensorboard_log')    \n",
    "\n",
    "# 경사하강법을 1000번 수행합니다.\n",
    "for i in range(1000):\n",
    "  train_step(x_train, y_train)\n",
    "\n",
    "# 테스트를 위한 입력값을 준비합니다.\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n",
    "# 예상되는 참값 : [7, 10, 11, 12]\n",
    "print(linear_model(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19148), started 0:01:50 ago. (Use '!kill 19148' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c29a57aaf9d28019\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c29a57aaf9d28019\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tensorboard_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

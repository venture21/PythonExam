{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnistWithCNN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7uHGe1bIxzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#mnist데이터셋을 다운로드 한다.\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBWBBdxpTQsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN모델을 정의\n",
        "def build_CNN_classifier(x):\n",
        "  #mnist 3차원 형태로 reshape 28*28*1\n",
        "  x_image = tf.reshape(x, [-1,28,28,1])\n",
        "\n",
        "  #1st conv2d\n",
        "  # 5x5 32 filter(channel)\n",
        "  # 28x28x1 -> 28x28x32\n",
        "  W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32], stddev=5e-2))\n",
        "  b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
        "  h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1,strides=[1,1,1,1],padding='SAME')+b_conv1)\n",
        "  #1st max pooling\n",
        "  #입력 이미지를 1/2로 다운샘플링\n",
        "  # 28x28x32 -> 14x14x32\n",
        "  h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "  #2nd conv2d\n",
        "  # 5x5 64 filter(channel)\n",
        "  # 14x14x32 -> 14x14x64\n",
        "  W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64], stddev=5e-2))\n",
        "  b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "  h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2)\n",
        "  #2nd max pooling\n",
        "  #입력 이미지를 1/2로 다운샘플링\n",
        "  # 14x14x64 -> 7x7x64\n",
        "  h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "  #Fully connected Layer\n",
        "  #7x7x64(3136) -> 1024\n",
        "  # 7x7크기를 가진 64개의 activation map을 1024개의 feature로 변환\n",
        "  W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64,1024], stddev=5e-2))\n",
        "  b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))\n",
        "  h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "  h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)\n",
        "\n",
        "  #output Layer\n",
        "  #1024개의 특징들을 10개의 클래스로 변환한다.\n",
        "  W_output = tf.Variable(tf.truncated_normal(shape=[1024, 10], stddev=5e-2))\n",
        "  b_output = tf.Variable(tf.constant(0.1, shape=[10]))\n",
        "  logits = tf.matmul(h_fc1, W_output)+b_output\n",
        "  y_pred = tf.nn.softmax(logits)\n",
        "\n",
        "  return y_pred, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK9ZHNove8K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder정의\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "# Parameter\n",
        "learningRate = 1e-4\n",
        "epochs = 10000\n",
        "batchSize = 50\n",
        "displayStep = 100\n",
        "\n",
        "y_pred, logits = build_CNN_classifier(x)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss)\n",
        "\n",
        "#학습이 끝나면 모델의 정확도를 확인한다.\n",
        "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxr6qvhFfsjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  #epoch만큼 최적화를 수행한다.\n",
        "  for i in range(epochs):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    if i % displayStep ==0:\n",
        "      train_acuuracy = accuracy.eval(feed_dict={x:batch[0], y:batch[1]})\n",
        "      print(\"Epoch: %d, train_acuuracy: %f\" %((i+1), train_acuuracy))\n",
        "    sess.run([train_step], feed_dict={x:batch[0], y:batch[1]}) \n",
        "\n",
        "  print(\"Accuracy: %f\" %(accuracy.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels}))) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}